\documentclass[00-GLMregslides.tex]{subfiles}
\begin{document}
%=========================================%
\begin{frame}
\frametitle{Ordered logistic regression with \texttt{R} }
\textbf{Ordered logit model}

\begin{itemize}
\item The Ordered (or Ordinal) logit model (also ordered logistic regression or proportional odds model), is a regression model for ordinal dependent variables. 
\item For example, questions on a survey answered by a choice among "poor", "fair", "good", "very good", and "excellent".
\item The purpose of 
the analysis is to see how well that response can be predicted by the responses to other questions, some of which may be quantitative
\end{itemize}

\end{frame}

%========================================================%

\begin{frame}
\frametitle{Ordered logistic regression with \texttt{R} }
\Large
\textbf{Ordered logit model}

\begin{itemize}
\item It can be thought of as an extension of the 
logistic regression model that applies to dichotomous dependent variables, allowing for more than two (ordered) response categories.
\item The model only applies to data that meet the proportional odds assumption
\end{itemize}
\end{frame}
%========================================================%


%================================================ %
\begin{frame}[fragile]
\frametitle{Ordered logistic regression with \texttt{R} }
	\Large
\textbf{\texttt{polr}}
\begin{itemize}
\item In this section we will use the \texttt{polr} command (from the MASS package) to estimate an ordered logistic 
regression model. 
\item The command name comes from \textbf{\textit{proportional odds logistic regression}}, due to the the \textbf{\textit{proportional odds assumption}} in the model. 
\end{itemize}
\end{frame}

%================================================ %
\begin{frame}[fragile]
\frametitle{Ordered logistic regression with \texttt{R} }
	\Large
\textbf{\texttt{polr}}
\begin{itemize}
\item \texttt{polr} uses the standard formula interface in \texttt{R} for specifying a regression model with outcome 
followed by predictors. 
\item We will also specify \texttt{Hess=TRUE} to have the model return the observed information matrix from optimization (called the Hessian) which is used to get standard errors.
\end{itemize}
\end{frame}

%================================================ %
\begin{frame}[fragile]
\frametitle{Ordered logistic regression with \texttt{R} }
\large
\begin{framed}		
\begin{verbatim}
	
## fit ordered logit model and store results 'm'
m <- polr(apply ~ pared + 
          public + gpa, data = dat, Hess=TRUE)

## view a summary of the model
summary(m)
## Call:
## polr(formula = apply ~ pared + 
             public + gpa, data = dat, 
             Hess = TRUE)
\end{verbatim}
\end{framed}
\end{frame}


%================================================ %
\begin{frame}[fragile]
\frametitle{Ordered logistic regression with \texttt{R} }
	\normalsize
\begin{verbatim}
Coefficients:
         Value Std. Error t value
pared   1.0477      0.266   3.942
public -0.0588      0.298  -0.197
gpa     0.6159      0.261   2.363

Intercepts:
                            Value  Std. Error t value
unlikely|somewhat likely     2.204  0.780      2.827 
somewhat likely|very likely  4.299  0.804      5.345 

\end{verbatim}

% Residual Deviance: 717.02 
% AIC: 727.02
\end{frame}

%================================================ %
\begin{frame}[fragile]
\frametitle{Ordered logistic regression with \texttt{R} }
	\Large
\begin{itemize}
\item[1] The ``Call", what type of model we ran, what options we specified, etc.
\item[2] The usual regression output coefficient table including the value of each coefficient, standard errors, and 
$t-$value, which is simply the ratio of the coefficient to its standard error.\\ (Remark: There is no significance test by default.)
\end{itemize}
\end{frame}

%================================================ %
\begin{frame}
\frametitle{Ordered logistic regression with \texttt{R} }
	\Large
\begin{itemize}
\item[3]	
We then have the estimates for the two intercepts (which are sometimes called \textbf{\textit{cutpoints}}). 
\item[4] The intercepts indicate where the latent variable is cut to make the three groups that we observe in our data. 
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Ordered logistic regression with \texttt{R} }
\Large

In the ordered logit model, there is an observed ordinal variable, Y.
Y, in turn, is a function of another latent variable, Y*, that is not measured.

\begin{itemize}
\item[a.] In the ordered logit model, there is a continuous, unmeasured latent variable Y*,
whose values determine what the observed ordinal variable Y equals.
\item[b.] The continuous latent variable Y* has various threshold (or cutoff) points. 
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Ordered logistic regression with \texttt{R} }
\Large
Your value on the
observed ordinal variable Y depends on whether or not you have crossed a particular threshold. For
example, when M = 3
\begin{itemize}
\item Yi = 1 if Y*i is $ \le $ CP1
\item Yi = 2 if CP1 $ \le $ Y*i $ \le $ CP2
\item Yi = 3 id Y*i $ \ge $ CP2
\end{itemize}
\end{frame}
%================================================ %
\begin{frame}[fragile]
	\frametitle{Ordered logistic regression with \texttt{R} }
	\Large

\begin{itemize}
\item Note that this latent variable is continuous. In general, these are not used in the interpretation of the results. \item  The cutpoints are closely related to thresholds, which are reported by other statistical packages.
\end{itemize}
\end{frame}
%================================================ %
\begin{frame}[fragile]
	\frametitle{Ordered logistic regression \texttt{R} }
	\Large
\textbf{Model Diagnostics}
\begin{itemize}
\item We see the residual deviance, -2 * Log Likelihood of the model as well as the AIC. 
\item Both the deviance and AIC are useful for model comparison.
\item Of, course, some people are not satisfied without a $p-$value.
\item One way to calculate a $p-$value in this case is by comparing the $t-$value against the standard normal distribution, like a $z-$test. 
\end{itemize}
\end{frame}
%================================================ %
\begin{frame}[fragile]

\frametitle{Ordered logistic regression \texttt{R} }

	\Large
\begin{itemize}
\item Of course this is only true with infinite degrees of freedom, but is reasonably approximated by large 
samples, becoming increasingly biased as sample size decreases. 

%\item This approach is used in other software packages such as Stata and is trivial to do. 

\item First we store the coefficient table, then calculate the $p-$values and combine back with the table.

\end{itemize}
\end{frame}


%================================================ %
\begin{frame}[fragile]
\frametitle{Ordered logistic regression \texttt{R} }
\normalsize
\begin{verbatim}
		
# store table
(ctable <- coef(summary(m)))
                                Value Std. Error t value
 pared                        1.04769     0.2658  3.9418
 public                      -0.05879     0.2979 -0.1974
 gpa                          0.61594     0.2606  2.3632
 unlikely|somewhat likely     2.20391     0.7795  2.8272
 somewhat likely|very likely  4.29936     0.8043  5.3453
 
 

\end{verbatim}

\end{frame}
%================================================ %
\begin{frame}[fragile]
	\frametitle{Ordered Logistic regression \texttt{R} }
\normalsize	
	\begin{verbatim}
# calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), 
      lower.tail = FALSE) * 2

# Combined table
(ctable <- cbind(ctable, "p value" = p))
                      Value Std. Error t value   p value
 pared              1.04769     0.2658  3.9418 8.087e-05
 public            -0.05879     0.2979 -0.1974 8.435e-01
 gpa                0.61594     0.2606  2.3632 1.812e-02
 unli..|some..      2.20391     0.7795  2.8272 4.696e-03
 some..|very..      4.29936     0.8043  5.3453 9.027e-08
\end{verbatim}

\end{frame} 

%================================================ %
\end{document}
